# Data Center Platform

## Outline
In this unit we will cover:
- Data Center Platform
- GPUs and CPUs fro AI Data Centers
- Multi-GPU Systems
- Introducing DPUs
- NVIDIA-Certified Systems

## Objectives
By the end of this unit, you will be able to:
- Indicate the key components and features of the NVIDIA data center platform
- Identify the GPU and CPU requirements for AI data centers, the different products available and their intented use cases
- Understand the purpose and capabilities of multi-GPU systems
- Describe the multi-node GPU interconnect technology
- Determine the role of DPUs and DOCA in an AI data center

## Keywords
Here are the key extracted keywords:

- Compute Platforms for AI
- Data center platform
- GPUs, CPUs, DPUs
- NVIDIA-certified systems
- Multi-GPU systems
- Multi-node GPU interconnect technology
- DOCA
- CUDA
- Accelerated computing
- Full stack challenge
- Software libraries (CUDA-X)
- Application frameworks (Riva, DRIVE, Merlin)
- AI, high-performance computing
- Autonomous machines
- Cloud-native, cloud computing frameworks
- Cloud service providers (CSPs)
- NVIDIA DGX systems
- AI workflow
- Data scientists, data engineers, DevOps
- GPU-accelerated AI
- Edge computing
- Jetson platform
- Real-time decision-making
- Virtual workstations and desktops
- Optimized containers