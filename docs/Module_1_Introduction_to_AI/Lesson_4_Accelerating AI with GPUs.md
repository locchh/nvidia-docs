# Accelerating AI with GPUs

## Outline
In this unit we will cover:
- GPU History
- GPU Architecture
- CPUs vs GPUs
- GPU Server Systems
- NVIDIA GPU architecture

## Objectives
By the end of this unit, you will be able to:
- Recall GPU history and key developments
- Explain GPU architecture and its functionality
- Analyze VPU vs GPU differences
- Apply GPU server system knowledge
- Evaluate NVIDIA's AI GPU families

## Keywords
Here are the extracted keywords from the text:

- **Nvidia GPUs**
- **Accelerated compute**
- **GPU history**
- **GPU architecture**
- **CPUs vs GPUs**
- **GPU server systems**
- **Data center**
- **Nvidia AI GPU families**
- **Deep learning**
- **Parallel processing**
- **AI models**
- **Compute power**
- **Mooreâ€™s Law**
- **Data processing**
- **PCIe bus**
- **NVLink**
- **GPU memory**
- **Cache memory**
- **Triton server**
- **NGC**
- **Grace Hopper GH200**
- **CUDA**
- **HPC (High-Performance Computing)**
- **Cloud service providers**
- **AI software ecosystem**
- **AI training and inference**
- **Edge computing**
- **Virtualization**
- **Visualization**
- **Workstations**
- **Nvidia DGX H100**
- **Nvidia HGX H100**
- **Nvidia MGX**
- **PCIe form factor**
- **SXM form factor**
